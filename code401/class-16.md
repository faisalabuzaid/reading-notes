# Data Science Primer:

  - ## Bird's Eye View:
 
    - This data science primer will cover exploratory analysis, data cleaning, feature engineering, algorithm selection, and model training. 
    - What makes machine learning so special?
      - Machine learning is the practice of teaching computers how to learn patterns from data, often for making decisions or predictions.
      - Model - a set of patterns learned from data.
      - Algorithm - a specific ML process used to train a model.
      - Training data - the dataset from which the algorithm learns the model.
      - Test data - a new dataset for reliably evaluating model performance.
      - Features - Variables (columns) in the dataset used to train the model.
      - Target variable - A specific variable you're trying to predict.
      - Observations - Data points (rows) in the dataset.
      - Machine Learning Tasks:Academic machine learning starts with and focuses on individual algorithms.
      - However, in applied machine learning, you should first pick the right machine learning task for the job.
      - categories of tasks are supervised learning and unsupervised learning.
      - **The Blueprint**:
          - 1 - Exploratory Analysis: First, "get to know" the data. This step should be quick, efficient, and decisive.
          - 2 - Data Cleaning: Then, clean your data to avoid many common pitfalls. Better data beats fancier algorithms.
          - 3 - Feature Engineering: Next, help your algorithms "focus" on what's important by creating new features.
          - 4 - Algorithm Selection: Choose the best, most appropriate algorithms without wasting your time.
          - 5 - Model Training: Finally, train your models. This step is pretty formulaic once you've done the first 4.
      - there are other situational steps as well:
          - S - Project Scoping: Sometimes, you'll need to roadmap the project and anticipate data needs.
          - W - Data Wrangling: You may also need to restructure your dataset into a format that algorithms can handle.
          - P - Preprocessing: Often, transforming your features first can further improve performance.
          - E - Ensembling: You can squeeze out even more performance by combining multiple models.
     - ## Exploratory Analysis:
        - Why explore your dataset upfront?
        - The purpose of exploratory analysis is to "get to know" the dataset. 
        - in 3 main ways:
          - You’ll gain valuable hints for Data Cleaning (which can make or break your models).
          - You’ll think of ideas for Feature Engineering (which can take your models from good to great).
          - You’ll get a "feel" for the dataset, which will help you communicate results and deliver greater impact.
        -  exploratory analysis for machine learning should be quick, efficient, and decisive... not long and drawn out!
        - Start with Basics:
          - How many observations do I have?
          - How many features?
          - What are the data types of my features? Are they numeric? Categorical?
          - Do I have a target variable?
        - **Plot Categorical Distributions**:
          - Categorical features cannot be visualized through histograms. Instead, you can use bar plots.
          - In particular, you'll want to look out for sparse classes, which are classes that have a very small number of observations.
          - By the way, a "class" is simply a unique value for a categorical feature. 
          - when building models.
            - In the best case, they don't influence the model much.
            - In the worse case, they can cause the model to be overfit.
        - **Plot Segmentations**:
          - The median transaction price (middle vertical bar in the box) for Single-Family homes was much higher than that for Apartments / Condos / Townhomes.
          - The min and max transaction prices are comparable between the two classes.
          - In fact, the round-number min ($200k) and max ($800k) suggest possible data truncation...
          - ...which is very important to remember when assessing the generalizability of your models later!
         
       - ## Data Cleaning
         - Proper data cleaning is the “secret” sauce behind machine learning.
         - Better data beats fancier algorithms…
         -  If you have a clean dataset, even simple algorithms can learn impressive insights from it!
       - ## Feature Engineering:
         - In a nutshell, “feature engineering” is creating new model input features from your existing ones.
         - To start, feature engineering is very open-ended. There are literally infinite options for new features to create.
         - Plus, you’ll need domain knowledge to add informative features instead of more noise.
       - ## Algorithm Selection:
         - our goal is to explain a few essential concepts (e.g. regularization, ensembling, automatic feature selection) that will teach you why some algorithms tend to perform better than others.
         - In applied machine learning, individual algorithms should be swapped in and out depending on which performs best for the problem and the dataset.
         - We have two main goals:
           - 1 - To explain powerful mechanisms in modern ML.
           - 2 - To introduce several algorithms that use those mechanisms.
      - ## Model Training:
        - data scientists actually do spend most their time on the earlier steps:
           - 1 - Exploring the data.
           - 2 - Cleaning the data.
           - 3 - Engineering new features.
        - Now you'll learn how to maximize model performance while safeguarding against overfitting.
        - Plus, you'll learn how to automatically find the best parameters for each algorithm.